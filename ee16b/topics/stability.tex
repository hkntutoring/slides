\section{Stability}

\begin{frame}{Stability in Discrete Time}

A discrete system is stable iff all eigenvalues have magnitude less than 1. If any eigenvalue has magnitude greater than 1, then any state vector with a nonzero corresponding eigenvector component will have that component repeatedly magnified.

    For example: \(x[t+1] = 2 x[t]\)

\end{frame}

\begin{frame}{Stability in Discrete Time}
A discrete system is stable iff
    \[
        \forall x \in eig(A) : |x| < 1
    \]

The eigenvectors form a basis (called the eigenbasis) which spans the entire space if A is full rank. (can you prove this?)

If any eigenvalue has magnitude greater than 1, then any state vector with a nonzero corresponding eigenvector component will have that component repeatedly magnified.
\end{frame}

\begin{frame}{Stability in Discrete Time}

How do the eigenvalues govern system dynamics?

    If initial state is x(0), and there's no control input, the \(n\)th state is
    \[
        x(n) = A^n x(0)
    \]

    If any eigenvalue of \(A\) is larger in magnitude than \(1\), it ``blows up'' through repeated exponentiation - the system destabilizes!
\end{frame}

\begin{frame}{Stability in Discrete Time}
    \includegraphics[width=\textwidth]{./images/eigenvalues-on-the-unit-circle}
\end{frame}

\begin{frame}{Stability in Continuous Time}

A continuous system is stable iff the real parts of all eigenvalues are negative. If any eigenvalue is positive, then any state vector with a nonzero corresponding eigenvector component will have that component grow exponentially to infinity.

    For example: \(\ddt{}x(t) = 2\,x(t)\)

\end{frame}

\begin{frame}{Stability in Continuous Time}

    \[
        \ddt{} x(t) = a x(t) + b u(t)
    \]

    \[
        x(t) = e^{at} x(0) + b \int_0^t e^{a(t - s)} u(s) \,\differential s
    \]

    For scalar case, system is stable if \(\mathrm{Re}\{a\} < 0\) and not stable if \(\mathrm{Re}\{a\} > 0\).

    By careful application of diagonalization, we get the same result for the eigenvalues of \(A\) in the matrix case.

\end{frame}

\begin{frame}{Stability in Continuous Time}
    \includegraphics[width=\textwidth]{./images/cont-stability}
\end{frame}

\begin{frame}{Stability in Continuous Time}
How do the eigenvalues govern system dynamics?

    If initial state is \(\vec x(0)\), and there's no control input, state at time \(t\) is
    \[
        \vec x(t) = e^{At} \vec x(0)
    \]
    If any eigenvalue of \(A\) is larger in magnitude than \(1\), it ``blows up'' through repeated exponentiation --- the system destabilizes!
\end{frame}


\begin{frame}{Stability Through State Feedback}

\begin{columns}[T] % align columns
\begin{column}{.48\textwidth}
%\color{red}\rule{\linewidth}{4pt}
%
%Left Part
    \begin{itemize}
        \item If we add a feedback path (modifying the input values with the state) our state update equation changes \[ \vec x(t + 1) = (A + BK) \vec x(t)\]
        \item What determines the stability of this new system?
    \end{itemize}

\end{column}%
\hfill%
\begin{column}{.48\textwidth}
    \includegraphics[width=\textwidth]{./images/block-diagram-of-system.png}

\end{column}%
\end{columns}

\end{frame}

\begin{frame}{State Feedback}
    \begin{itemize}
        \item
By designing K, we can give our system specific dynamic properties
            \begin{itemize}
        \item
Can analyze and design the way its state changes over time
            \end{itemize}
        \item
If our “open-loop” system is unstable, choosing the right values of K can make it stable!
        \item
Is this always possible?
    \end{itemize}
\end{frame}

\begin{frame}{Example: Controllability and Stability}
    \[
        \vec x[t + 1] = \begin{bmatrix}
            -5 & 0 \\
            7 & 6
            \end{bmatrix} \vec x[t] +  \begin{bmatrix} 2 \\ -1\end{bmatrix} u[t]
    \]

   Controllable?
            \onslide<2->{{\bfseries Yes}}

    Stable for \(u[t] = 0\)?
            \onslide<3->{{\bfseries No}}
\end{frame}
